# HTTP 503 Error Analysis - Connection Reset Investigation

## Executive Summary

This analysis investigates intermittent HTTP 503 errors observed in the eKYC service running on Kubernetes with Istio service mesh. Through multi-layer verification using Istio debug logs, TCP packet capture, and application performance monitoring, we determined the following:

**Key Finding:**  
The HTTP 503 error was generated by **Envoy (Istio sidecar proxy)**, NOT by the application itself. However, the root cause originates from the **application layer** - specifically, the application terminated TCP connections without sending HTTP responses, causing Envoy to generate 503 errors as a protective measure.


**Verification Methods:**
1. ‚úÖ Istio debug logs analysis
2. ‚úÖ TCP packet capture (tcpdump) at POD level
3. ‚úÖ Node.js Event Loop monitoring (Dynatrace APM)
4. ‚úÖ In-container process inspection
5. ‚úÖ Idle timeout configuration testing

---

## Incident Details

### Connection Information
- **Downstream Connection** (Client ‚Üí Envoy): ConnectionId `10487`
- **Upstream Connection** (Envoy ‚Üí Application): ConnectionId `161542`
- **Stream ID**: `16478996913353721676`
- **Thread**: `22`
- **Target Endpoint**: `/health`
- **HTTP Method**: `GET`
- **Application IP**: `100.65.14.224:8080`

### Timeline
- **Request Received**: `2025-10-09T03:19:40.196137Z`
- **Connection Lifetime**: ~32 seconds (connection created at 03:19:10.359705Z)
- **Request Processing Time**: ~1.956 seconds
- **503 Error Generated**: `2025-10-09T03:19:42.152239Z`

---

## Detailed Timeline Analysis

The following sequence reconstructs the exact flow of events from Istio debug logs:

### Step 1: Request Initiation (03:19:40.196137Z)
Envoy receives a health check request from the Istio ingress gateway:
```
[ConnectionId:10487] new stream
[ConnectionId:10487, StreamId:16478996913353721676] request headers complete (end_stream=true)
- Request: GET /health
- From: istio-ingressgateway
- x-request-id: 48b62f31-c07b-43a3-abb0-27f5627b34ec
```

### Step 2: Connection Pool Reuse (03:19:40.196349Z)
Envoy reuses an existing upstream connection to optimize performance:
```
[ConnectionId:161542] using existing fully connected connection
[ConnectionId:161542] creating stream
```
**Note**: Connection `161542` was created ~30 seconds earlier at `03:19:10.359705Z` and had successfully served multiple requests.

### Step 3: Request Forwarded (03:19:40.196374Z)
The request is successfully forwarded to the application container:
```
[ConnectionId:10487, StreamId:16478996913353721676] pool ready
[ConnectionId:161542] encode complete
```

### Step 4: ‚ö†Ô∏è Connection Terminated by Application (03:19:42.152160Z)
**Critical Event**: The application closes the connection without sending a response:
```
‚ö†Ô∏è  [ConnectionId:161542] closing socket: 0
‚ö†Ô∏è  [ConnectionId:161542] disconnect. resetting 1 pending requests
‚ö†Ô∏è  [ConnectionId:161542] Request reset. Reason 7
```

**Reset Reason 7** = `ConnectionTermination` - The connection was abruptly closed/terminated.

### Step 5: Envoy Detects Reset (03:19:42.152239Z)
Envoy detects the upstream connection failure:
```
üî¥ [ConnectionId:10487, StreamId:16478996913353721676] 
   upstream reset: reset reason: connection termination, transport failure reason: 
```

### Step 6: Envoy Generates 503 Response (03:19:42.152275Z)
Since no response was received, Envoy generates a local 503 error:
```
üî¥ [ConnectionId:10487, StreamId:16478996913353721676] 
   Sending local reply with details upstream_reset_before_response_started{connection_termination}
```

### Step 7: 503 Sent to Client (03:19:42.152315Z)
```
':status', '503'
'content-length', '95'
'content-type', 'text/plain'
'date', 'Thu, 09 Oct 2025 03:19:41 GMT'
'server', 'istio-envoy'

Body: upstream connect error or disconnect/reset before headers. reset reason: connection termination
```

---

## Root Cause Analysis

### What Actually Happened

1. ‚úÖ Health check request received by Envoy sidecar
2. ‚úÖ Envoy reused an existing connection (ConnectionId: 161542) from the connection pool
3. ‚úÖ Request successfully transmitted to the application at 100.65.14.224:8080
4. ‚ö†Ô∏è After **~1.956 seconds**, the application closed the TCP connection **without sending any HTTP response**
5. üî¥ Envoy detected the connection termination with 1 pending request
6. üî¥ Envoy generated a **503 Service Unavailable** error as a protective response

### Connection Reset vs. Normal Closure

**This was an ABNORMAL connection reset, not a graceful closure.**

| Normal Behavior | Observed Behavior |
|----------------|-------------------|
| Application sends HTTP response | ‚ùå No response sent |
| Application closes connection after response | ‚ùå Connection closed before response |
| Envoy forwards response to client | ‚ùå Envoy generates 503 error |
| No error logged | ‚ùå `Request reset. Reason 7` logged |
| Status code from application | ‚ùå Envoy-generated 503 |

### Evidence from Logs

- `closing socket: 0` - Socket closed with reason code 0
- `disconnect. resetting 1 pending requests` - Connection closed while request was in-flight
- `Request reset. Reason 7` - Explicit connection termination
- `upstream reset: reset reason: connection termination` - Classified as upstream failure
- **Zero bytes of HTTP response received** before connection closed

---

### 1Ô∏è‚É£ TCP Packet Capture (tcpdump) - POD Level

**Objective**: Verify Istio debug log findings by capturing actual network traffic between Envoy and the application container.

**Method**:
- Executed `tcpdump` inside the POD
- Captured traffic between Envoy sidecar (127.0.0.6) and application container
- Analyzed TCP flags and HTTP payload during 503 error occurrences

**Findings**:

‚úÖ **TCP dump confirms Istio debug logs exactly:**

1. **Request Sent**: HTTP GET request to `/health` transmitted with `PSH, ACK` flags
2. **Application Acknowledged**: Application responded with `ACK`, confirming it received the request
3. **Connection Reset**: Application sent `RST, ACK` flags **without any HTTP response data**
4. **Zero Response Bytes**: No HTTP status line, headers, or body captured before RST

**TCP Flag Sequence**:
```
Envoy ‚Üí Application:  PSH, ACK  (HTTP request sent)
Application ‚Üí Envoy:  ACK       (Request acknowledged)
Application ‚Üí Envoy:  RST, ACK  (Connection terminated later)
```

**Conclusion**: TCP-level verification eliminates any doubt that the connection reset originated from the application layer, NOT from network infrastructure or Envoy proxy.

---

### 2Ô∏è‚É£ In-Container Process Inspection

**Objective**: Investigate potential resource exhaustion or process management issues inside the application container.

**Critical Finding**:

üö® **Approximately ~2000+ zombie/defunct `phantomjs` processes discovered**


**Characteristics**:
- Process status: `Z` (zombie) or `<defunct>`
- CPU usage: 0%
- Memory: 0 (memory already released)
- **Problem**: Consuming process table entries (PID slots)

**Why This Causes 503 Errors**:
- When the process table is exhausted, the application **cannot fork child processes** or handle certain operations
- This can cause the application to **terminate connections abruptly** without responding
- Resource exhaustion explains the **sudden connection resets** observed in Istio logs

**Root Cause of Zombie Processes**:
- Parent process (Node.js application) is not properly reaping child processes
- Missing or improper `wait()` / `waitpid()` system calls
- Likely caused by improper child process management in `phantomjs` integration code

**Immediate Recommendations**:
1. **Code Review**: Investigate `phantomjs` usage in codebase - check child process spawning/cleanup file: ` ./node_modules/phantomjs-prebuilt/bin/phantomjs`
```
#!/usr/bin/env node

/**
* Script that will execute the downloaded phantomjs binary.  stdio are
* forwarded to and from the child process.
*
* The following is for an ugly hack to avoid a problem where the installer
* finds the bin script npm creates during global installation.
*
* {NPM_INSTALL_MARKER}
*/

var path = require('path')
var spawn = require('child_process').spawn

var binPath = require(path.join(__dirname, '..', 'lib', 'phantomjs')).path

var args = process.argv.slice(2)

// Enhanced error handling and zombie process prevention
var cp = null
var isExiting = false
var timeoutHandle = null

// Timeout configuration (30 seconds default)
var PHANTOM_TIMEOUT = process.env.PHANTOM_TIMEOUT || 30000

function cleanup() {
  if (isExiting) return
  isExiting = true

  // Clear any pending timeout
  if (timeoutHandle) {
    clearTimeout(timeoutHandle)
    timeoutHandle = null
  }

  // Kill child process if it still exists
  if (cp && !cp.killed) {
    console.error('Cleaning up PhantomJS process...')

    // Try graceful termination first
    cp.kill('SIGTERM')

    // Force kill after 5 seconds if not terminated
    setTimeout(() => {
      if (cp && !cp.killed) {
        console.error('Force killing PhantomJS process...')
        cp.kill('SIGKILL')
      }
    }, 5000)
  }
}

function exitWithCode(code) {
  cleanup()
  // Wait few ms for error to be printed and cleanup to complete
  setTimeout(function() {
    process.exit(code)
  }, 100)
}

try {
  // For Node 0.6 compatibility, pipe the streams manually, instead of using
  // `{ stdio: 'inherit' }`.
  cp = spawn(binPath, args, {
    // Detach child process to prevent it from inheriting parent's stdio
    detached: false,
    // Set a reasonable timeout
    timeout: PHANTOM_TIMEOUT
  })

  // Pipe streams
  cp.stdout.pipe(process.stdout)
  cp.stderr.pipe(process.stderr)
  process.stdin.pipe(cp.stdin)

  // Set up timeout to prevent hanging processes
  timeoutHandle = setTimeout(() => {
    if (!isExiting && cp && !cp.killed) {
      console.error(`PhantomJS process timed out after ${PHANTOM_TIMEOUT}ms`)
      cleanup()
      process.exit(1)
    }
  }, PHANTOM_TIMEOUT)

  cp.on('error', function (err) {
    console.error('Error executing phantom at', binPath)
    console.error(err.stack)

    // Exit with error code to prevent hanging
    exitWithCode(1)
  })

  cp.on('exit', function(code, signal) {
    // Clear timeout since process has exited
    if (timeoutHandle) {
      clearTimeout(timeoutHandle)
      timeoutHandle = null
    }

    if (signal) {
      console.error(`PhantomJS process killed with signal ${signal}`)
    }

    exitWithCode(code || 0)
  })

  // Handle process disconnection
  cp.on('disconnect', function() {
    console.error('PhantomJS process disconnected')
    exitWithCode(1)
  })

  // Handle when child process closes all stdio streams
  cp.on('close', function(code, signal) {
    if (!isExiting) {
      if (signal) {
        console.error(`PhantomJS process closed with signal ${signal}`)
      }
      exitWithCode(code || 0)
    }
  })

} catch (err) {
  console.error('Failed to spawn PhantomJS process:', err.message)
  process.exit(1)
}

// Enhanced signal handling
process.on('SIGTERM', function() {
  console.error('Received SIGTERM, shutting down PhantomJS...')
  cleanup()
  process.exit(1)
})

process.on('SIGINT', function() {
  console.error('Received SIGINT, shutting down PhantomJS...')
  cleanup()
  process.exit(1)
})

process.on('SIGHUP', function() {
  console.error('Received SIGHUP, shutting down PhantomJS...')
  cleanup()
  process.exit(1)
})

// Handle uncaught exceptions
process.on('uncaughtException', function(err) {
  console.error('Uncaught exception in PhantomJS wrapper:', err.stack)
  cleanup()
  process.exit(1)
})

// Handle unhandled promise rejections
process.on('unhandledRejection', function(reason, promise) {
  console.error('Unhandled Rejection at:', promise, 'reason:', reason)
  cleanup()
  process.exit(1)
})

// Cleanup on normal exit
process.on('exit', function(code) {
  cleanup()
})

// Handle Windows-specific signals
if (process.platform === 'win32') {
  require('readline').createInterface({
    input: process.stdin,
    output: process.stdout
  }).on('SIGINT', function () {
    process.emit('SIGINT')
  })
}
```
2. **Replace phantomjs**: Consider migrating to **Puppeteer** (headless Chrome) - actively maintained and better process management
3. **Add Monitoring**: Alert on zombie process count and PID table utilization
4. **Test Post-Fix**: Perform controlled load test after remediation

---

### 3Ô∏è‚É£ Idle Timeout Configuration Testing

**Hypothesis**: Connection reset might be caused by idle timeout mismatch between Envoy and the application.

**Configuration Analysis**:
- **Application idle timeout**: 120 seconds
- **Istio/Envoy default idle timeout**: 1 hour (3600 seconds)
- **Mismatch**: Yes - application times out connections earlier than Envoy expects

**Test Performed**:
To eliminate this as a root cause, we adjusted Envoy's idle timeout to align with the application:

```bash
kubectl patch destinationrule torpedo-kyc-service -n kyc-sit \
  --type merge \
  -p '{"spec":{"trafficPolicy":{"connectionPool":{"http":{"idleTimeout":"60s"}}}}}'
```

**Result**:
‚ùå **503 errors continued to occur after applying the timeout configuration**

**Conclusion**:
While idle timeout mismatches can cause connection issues in some scenarios, this experiment proves it is **NOT the root cause** in this case. The issue persisted regardless of timeout alignment.

---

### 4Ô∏è‚É£ Application Performance Monitoring (Dynatrace)

**Objective**: Analyze Node.js runtime health to identify performance degradation or event loop blocking.

**Metrics Monitored**:

#### Event Loop Monitor
- **Tick Frequency** (Blue Bars): How often the event loop cycles
- **Tick Duration** (Orange Line): How long each cycle takes
- **Healthy**: High frequency + Low duration
- **Degraded**: Low frequency + High duration (blocking operations)

#### Work Processed Latency
- Measures callback and I/O processing time
- **Healthy**: Low latency (<10ms)
- **Degraded**: High latency (task queue backup)

#### Event Loop Utilization
- Percentage of time event loop is actively working
- **Healthy**: 30-70%
- **Degraded**: >90% (saturation, delays other tasks)

#### Event Loop Latency
- Delay between callback scheduling and execution
- **Healthy**: Few milliseconds
- **Degraded**: High latency (busy loop, delayed callbacks)

#### Active Handles
- Open sockets, timers, file descriptors
- **Healthy**: Stable count
- **Degraded**: Growing count (resource leaks)

**Analysis Results**:

Based on Dynatrace metrics during 503 occurrences:

| Pattern | Metrics | Interpretation | Action |
|---------|---------|----------------|--------|
| ‚úÖ **Normal** | High tick freq, low latency, balanced utilization | Event loop healthy; issue in specific endpoint or external dependency | Focus on endpoint logic, zombie processes |
| ‚ö†Ô∏è **Degraded** | Low tick freq, high latency, high utilization | Event loop blocked, synchronous operations | Investigate blocking code, CPU-bound tasks |


---

